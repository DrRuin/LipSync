{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Mounting Drive<b><h2>"
      ],
      "metadata": {
        "id": "YRFmJFMacPbZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU9Soxp_VWmq",
        "outputId": "2a103836-1a07-4c69-966c-e921c511166f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Installing Requirements<b><h2>"
      ],
      "metadata": {
        "id": "AxGSivmbcEe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa==0.8.0\n",
        "!pip install ffmpeg\n",
        "!pip install numpy==1.20.1\n",
        "!pip install opencv-contrib-python\n",
        "!pip install opencv-python\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install tqdm\n",
        "!pip install numba==0.48"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YO9XaV4eLT1",
        "outputId": "969dc53b-2ed9-425b-d5fd-b9a87b7d4ede"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa==0.8.0 in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.3.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (0.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.6.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.43.0->librosa==0.8.0) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.43.0->librosa==0.8.0) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.8.0) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.8.0) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.8.0) (2.27.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.0) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.9.0->librosa==0.8.0) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.8.0) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Downloading Video And Audio<b><h2>"
      ],
      "metadata": {
        "id": "r6Mgtr2GbuZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "\n",
        "#Setting progress\n",
        "def progress_func(stream, chunk, bytes_remaining):\n",
        "    current = ((stream.filesize - bytes_remaining)/stream.filesize)\n",
        "    percent = ('{0:.1f}').format(current*100)\n",
        "    progress = int(50*current)\n",
        "    status = 'â–ˆ' * progress + '-' * (50 - progress)\n",
        "    print('Downloading: [{0}] {1}%'.format(status, percent), end='\\r')\n",
        "\n",
        "#Allocating Link\n",
        "youtube_link = 'https://www.youtube.com/watch?v=YMuuEv37s0o'\n",
        "yt = YouTube(youtube_link, on_progress_callback=progress_func)\n",
        "\n",
        "# Getting best resolution video stream without audio\n",
        "video_stream = yt.streams.filter(only_video=True, file_extension='mp4').first()\n",
        "\n",
        "#Dowloading\n",
        "video_stream.download()\n",
        "\n",
        "#Once Finished , Print !\n",
        "print(\"Download finished.\")"
      ],
      "metadata": {
        "id": "IUuKRClBbGqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1jhUOAeGw8lPjNf7Q1cIcBOvzE3CJ3gVz'\n",
        "output = 'output10.wav'\n",
        "gdown.download(url, output, quiet=False)\n"
      ],
      "metadata": {
        "id": "PJEFW1Libpng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Once we finish downloading , we have to rename our video file name to video.mp4 , the code given below will only capture those frames where the face is visible and upto 1 minute and 8 sec..As Wav2lip depends on face<b><h2>"
      ],
      "metadata": {
        "id": "hgATtLezjAtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the face detector\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Load the video\n",
        "cap = cv2.VideoCapture('video.mp4')\n",
        "\n",
        "# Get the total number of frames and frames per second\n",
        "total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Calculate the number of frames for 1 minute and 8 seconds\n",
        "duration_frames = int(1 * 60 * fps + 8 * fps)  # 1 minute and 8 seconds\n",
        "\n",
        "# Prepare the video writer with the new fourcc and frame size\n",
        "frame_size = (3840, 1920)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('output.mp4', fourcc, fps, frame_size)\n",
        "\n",
        "# Initialize the progress bar\n",
        "pbar = tqdm(total=duration_frames)\n",
        "\n",
        "frames_written = 0\n",
        "while(cap.isOpened() and frames_written < duration_frames):\n",
        "    ret, frame = cap.read()\n",
        "    if ret == True:\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "        # If a face is detected and the frame is not None, write the frame to the output video\n",
        "        if len(faces) != 0 and frame is not None:\n",
        "            out.write(frame)\n",
        "            frames_written += 1\n",
        "\n",
        "        # Update the progress bar\n",
        "        pbar.update(1)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Close the progress bar\n",
        "pbar.close()\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ],
      "metadata": {
        "id": "yWDHx4mVi7PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><b>Now here we will use FFMpeg to meet Wav2lip requirements:\n",
        "\n",
        ">ffmpeg -i output.mp4 -r 25 input.mp4\n",
        ">ffmpeg -i input.mp4 -vf \"scale=1280:-1\" output.mp4\n",
        "<br>\n",
        "\n",
        "Here we are converting our video file to 1280 with 25 fps to make it easier for Wav2lip to do its work\n",
        "\n",
        "Note: Please make sure that you have ffmpeg installed , if not , then you can install it through pip or download it from here https://ffmpeg.org/download.html and set the path of bin folder in Environment Variables if you are working on PC"
      ],
      "metadata": {
        "id": "HlQZEPTpcXC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Rudrabha/Wav2Lip.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCfU01bxVv5F",
        "outputId": "41d9a7e3-21f8-4999-e8dd-9219ea04b008"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Wav2Lip' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/gdrive/MyDrive/Colab Notebooks\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZsZSUuAVzGt",
        "outputId": "fd64dd57-6df6-4b6f-b448-9b6612ce57c7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output10.wav  Untitled0.ipynb  video.mp4  wav2lip_gan.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -ri \"/content/gdrive/MyDrive/Colab Notebooks/wav2lip_gan.pth\" /content/Wav2Lip/checkpoints/"
      ],
      "metadata": {
        "id": "2sS0Aj6eeytZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84c7ed83-ced1-4673-e65b-655540a94492"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: overwrite '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'? yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq4pkzjbe87n",
        "outputId": "fd212295-fae7-4bd1-b9d6-fccf139ed4e4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-19 04:39:05--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
            "Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n",
            "Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89843225 (86M) [application/octet-stream]\n",
            "Saving to: â€˜Wav2Lip/face_detection/detection/sfd/s3fd.pthâ€™\n",
            "\n",
            "Wav2Lip/face_detect 100%[===================>]  85.68M  12.2MB/s    in 6.9s    \n",
            "\n",
            "2023-07-19 04:39:12 (12.4 MB/s) - â€˜Wav2Lip/face_detection/detection/sfd/s3fd.pthâ€™ saved [89843225/89843225]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls sample_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6--56Nqg7xn",
        "outputId": "b3fe8e3a-9715-4e31-a201-d89c0a3609fe"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anscombe.json\t\t      mnist_test.csv\t     README.md\n",
            "california_housing_test.csv   mnist_train_small.csv  video.mp4\n",
            "california_housing_train.csv  output10.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/gdrive/MyDrive/Colab Notebooks/video.mp4\" \"/content/gdrive/MyDrive/Colab Notebooks/output10.wav\" sample_data/\n",
        "!ls sample_data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2V8EQ1OhET9",
        "outputId": "f6ab6857-0572-4387-a6f6-06dc8f373581"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anscombe.json\t\t      mnist_test.csv\t     README.md\n",
            "california_housing_test.csv   mnist_train_small.csv  video.mp4\n",
            "california_housing_train.csv  output10.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path '../Wav2Lip/checkpoints/wav2lip_gan.pth' --face \"../sample_data/video.mp4\" --audio \"../sample_data/output10.wav\" --outfile \"outputs.mp4\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v1dcpKmjMQI",
        "outputId": "1a7eabc1-2a5d-473b-94ea-87f38f77e760"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 1702\n",
            "(80, 5386)\n",
            "Length of mel chunks: 1680\n",
            "  0% 0/14 [00:00<?, ?it/s]\n",
            "  0% 0/105 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 1/105 [00:41<1:11:25, 41.21s/it]\u001b[A\n",
            "  2% 2/105 [00:44<32:08, 18.73s/it]  \u001b[A\n",
            "  3% 3/105 [00:46<19:10, 11.28s/it]\u001b[A\n",
            "  4% 4/105 [00:49<13:07,  7.80s/it]\u001b[A\n",
            "  5% 5/105 [00:51<09:47,  5.88s/it]\u001b[A\n",
            "  6% 6/105 [00:54<07:50,  4.76s/it]\u001b[A\n",
            "  7% 7/105 [00:56<06:41,  4.10s/it]\u001b[A\n",
            "  8% 8/105 [00:59<05:47,  3.58s/it]\u001b[A\n",
            "  9% 9/105 [01:01<05:10,  3.23s/it]\u001b[A\n",
            " 10% 10/105 [01:04<04:46,  3.02s/it]\u001b[A\n",
            " 10% 11/105 [01:06<04:30,  2.88s/it]\u001b[A\n",
            " 11% 12/105 [01:09<04:25,  2.86s/it]\u001b[A\n",
            " 12% 13/105 [01:12<04:14,  2.77s/it]\u001b[A\n",
            " 13% 14/105 [01:14<04:05,  2.70s/it]\u001b[A\n",
            " 14% 15/105 [01:17<03:59,  2.67s/it]\u001b[A\n",
            " 15% 16/105 [01:20<03:56,  2.66s/it]\u001b[A\n",
            " 16% 17/105 [01:22<03:58,  2.71s/it]\u001b[A\n",
            " 17% 18/105 [01:25<03:53,  2.69s/it]\u001b[A\n",
            " 18% 19/105 [01:28<03:48,  2.66s/it]\u001b[A\n",
            " 19% 20/105 [01:30<03:43,  2.63s/it]\u001b[A\n",
            " 20% 21/105 [01:33<03:45,  2.68s/it]\u001b[A\n",
            " 21% 22/105 [01:36<03:42,  2.68s/it]\u001b[A\n",
            " 22% 23/105 [01:38<03:38,  2.66s/it]\u001b[A\n",
            " 23% 24/105 [01:41<03:33,  2.64s/it]\u001b[A\n",
            " 24% 25/105 [01:43<03:29,  2.62s/it]\u001b[A\n",
            " 25% 26/105 [01:46<03:31,  2.67s/it]\u001b[A\n",
            " 26% 27/105 [01:49<03:24,  2.63s/it]\u001b[A\n",
            " 27% 28/105 [01:51<03:20,  2.60s/it]\u001b[A\n",
            " 28% 29/105 [01:54<03:16,  2.58s/it]\u001b[A\n",
            " 29% 30/105 [01:56<03:13,  2.58s/it]\u001b[A\n",
            " 30% 31/105 [01:59<03:14,  2.63s/it]\u001b[A\n",
            " 30% 32/105 [02:02<03:09,  2.59s/it]\u001b[A\n",
            " 31% 33/105 [02:04<03:04,  2.56s/it]\u001b[A\n",
            " 32% 34/105 [02:07<03:01,  2.55s/it]\u001b[A\n",
            " 33% 35/105 [02:09<02:58,  2.55s/it]\u001b[A\n",
            " 34% 36/105 [02:12<03:01,  2.63s/it]\u001b[A\n",
            " 35% 37/105 [02:15<02:55,  2.59s/it]\u001b[A\n",
            " 36% 38/105 [02:17<02:52,  2.57s/it]\u001b[A\n",
            " 37% 39/105 [02:20<02:48,  2.56s/it]\u001b[A\n",
            " 38% 40/105 [02:22<02:45,  2.55s/it]\u001b[A\n",
            " 39% 41/105 [02:25<02:49,  2.65s/it]\u001b[A\n",
            " 40% 42/105 [02:28<02:45,  2.62s/it]\u001b[A\n",
            " 41% 43/105 [02:30<02:40,  2.60s/it]\u001b[A\n",
            " 42% 44/105 [02:33<02:36,  2.57s/it]\u001b[A\n",
            " 43% 45/105 [02:35<02:34,  2.58s/it]\u001b[A\n",
            " 44% 46/105 [02:38<02:35,  2.64s/it]\u001b[A\n",
            " 45% 47/105 [02:41<02:31,  2.62s/it]\u001b[A\n",
            " 46% 48/105 [02:43<02:28,  2.61s/it]\u001b[A\n",
            " 47% 49/105 [02:46<02:25,  2.59s/it]\u001b[A\n",
            " 48% 50/105 [02:48<02:22,  2.60s/it]\u001b[A\n",
            " 49% 51/105 [02:51<02:23,  2.66s/it]\u001b[A\n",
            " 50% 52/105 [02:54<02:19,  2.63s/it]\u001b[A\n",
            " 50% 53/105 [02:56<02:15,  2.60s/it]\u001b[A\n",
            " 51% 54/105 [02:59<02:11,  2.58s/it]\u001b[A\n",
            " 52% 55/105 [03:01<02:09,  2.59s/it]\u001b[A\n",
            " 53% 56/105 [03:04<02:10,  2.65s/it]\u001b[A\n",
            " 54% 57/105 [03:07<02:05,  2.61s/it]\u001b[A\n",
            " 55% 58/105 [03:09<02:01,  2.59s/it]\u001b[A\n",
            " 56% 59/105 [03:12<01:58,  2.57s/it]\u001b[A\n",
            " 57% 60/105 [03:14<01:55,  2.57s/it]\u001b[A\n",
            " 58% 61/105 [03:17<01:56,  2.64s/it]\u001b[A\n",
            " 59% 62/105 [03:20<01:52,  2.61s/it]\u001b[A\n",
            " 60% 63/105 [03:22<01:48,  2.58s/it]\u001b[A\n",
            " 61% 64/105 [03:25<01:45,  2.57s/it]\u001b[A\n",
            " 62% 65/105 [03:27<01:42,  2.57s/it]\u001b[A\n",
            " 63% 66/105 [03:30<01:42,  2.63s/it]\u001b[A\n",
            " 64% 67/105 [03:33<01:38,  2.60s/it]\u001b[A\n",
            " 65% 68/105 [03:35<01:35,  2.58s/it]\u001b[A\n",
            " 66% 69/105 [03:38<01:32,  2.57s/it]\u001b[A\n",
            " 67% 70/105 [03:41<01:36,  2.75s/it]\u001b[A\n",
            " 68% 71/105 [03:45<01:46,  3.12s/it]\u001b[A\n",
            " 69% 72/105 [03:49<01:54,  3.47s/it]\u001b[A\n",
            " 70% 73/105 [03:53<01:56,  3.64s/it]\u001b[A\n",
            " 70% 74/105 [03:57<01:55,  3.74s/it]\u001b[A\n",
            " 71% 75/105 [04:01<01:51,  3.71s/it]\u001b[A\n",
            " 72% 76/105 [04:04<01:46,  3.66s/it]\u001b[A\n",
            " 73% 77/105 [04:07<01:33,  3.34s/it]\u001b[A\n",
            " 74% 78/105 [04:10<01:25,  3.18s/it]\u001b[A\n",
            " 75% 79/105 [04:12<01:17,  2.98s/it]\u001b[A\n",
            " 76% 80/105 [04:15<01:12,  2.90s/it]\u001b[A\n",
            " 77% 81/105 [04:18<01:08,  2.85s/it]\u001b[A\n",
            " 78% 82/105 [04:21<01:11,  3.12s/it]\u001b[A\n",
            " 79% 83/105 [04:25<01:12,  3.29s/it]\u001b[A\n",
            " 80% 84/105 [04:28<01:09,  3.31s/it]\u001b[A\n",
            " 81% 85/105 [04:31<01:02,  3.10s/it]\u001b[A\n",
            " 82% 86/105 [04:34<00:57,  3.03s/it]\u001b[A\n",
            " 83% 87/105 [04:37<00:52,  2.89s/it]\u001b[A\n",
            " 84% 88/105 [04:39<00:47,  2.78s/it]\u001b[A\n",
            " 85% 89/105 [04:42<00:43,  2.72s/it]\u001b[A\n",
            " 86% 90/105 [04:44<00:40,  2.69s/it]\u001b[A\n",
            " 87% 91/105 [04:47<00:38,  2.73s/it]\u001b[A\n",
            " 88% 92/105 [04:50<00:34,  2.67s/it]\u001b[A\n",
            " 89% 93/105 [04:52<00:31,  2.63s/it]\u001b[A\n",
            " 90% 94/105 [04:55<00:28,  2.60s/it]\u001b[A\n",
            " 90% 95/105 [04:57<00:25,  2.60s/it]\u001b[A\n",
            " 91% 96/105 [05:00<00:23,  2.66s/it]\u001b[A\n",
            " 92% 97/105 [05:03<00:20,  2.62s/it]\u001b[A\n",
            " 93% 98/105 [05:05<00:18,  2.59s/it]\u001b[A\n",
            " 94% 99/105 [05:08<00:15,  2.57s/it]\u001b[A\n",
            " 95% 100/105 [05:10<00:12,  2.58s/it]\u001b[A\n",
            " 96% 101/105 [05:13<00:10,  2.65s/it]\u001b[A\n",
            " 97% 102/105 [05:16<00:07,  2.61s/it]\u001b[A\n",
            " 98% 103/105 [05:18<00:05,  2.58s/it]\u001b[A\n",
            " 99% 104/105 [05:21<00:02,  2.56s/it]\u001b[A\n",
            "100% 105/105 [05:23<00:00,  3.08s/it]\n",
            "Load checkpoint from: ../Wav2Lip/checkpoints/wav2lip_gan.pth\n",
            "Model loaded\n",
            "100% 14/14 [05:57<00:00, 25.52s/it]\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "\u001b[0;35m[mp3 @ 0x5d02673a80c0] \u001b[0m\u001b[0;33mEstimating duration from bitrate, this may be inaccurate\n",
            "\u001b[0mInput #0, mp3, from '../sample_data/output10.wav':\n",
            "  Duration: 00:01:07.32, start: 0.000000, bitrate: 96 kb/s\n",
            "    Stream #0:0: Audio: mp3, 44100 Hz, mono, fltp, 96 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    encoder         : Lavf59.27.100\n",
            "  Duration: 00:01:07.20, start: 0.000000, bitrate: 2200 kb/s\n",
            "    Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 1280x640 [SAR 1:1 DAR 2:1], 2196 kb/s, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (mp3 (mp3float) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
            "\u001b[0m\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mprofile High, level 3.1\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0m264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'outputs.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 1280x640 [SAR 1:1 DAR 2:1], q=-1--1, 25 fps, 12800 tbn, 25 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 aac\n",
            "frame= 1680 fps= 30 q=-1.0 Lsize=    9112kB time=00:01:07.33 bitrate=1108.6kbits/s speed= 1.2x    \n",
            "video:8491kB audio:571kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.560849%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mframe I:12    Avg QP:16.32  size: 42255\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mframe P:1080  Avg QP:20.75  size:  6095\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mframe B:588   Avg QP:23.74  size:  2728\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mconsecutive B-frames: 49.8%  7.5%  9.6% 33.1%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mmb I  I16..4: 24.8% 69.0%  6.2%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mmb P  I16..4:  1.6%  7.5%  0.2%  P16..4: 27.2%  6.0%  2.5%  0.0%  0.0%    skip:55.1%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mmb B  I16..4:  0.4%  2.1%  0.0%  B16..8: 29.3%  2.8%  0.3%  direct: 1.0%  skip:64.1%  L0:54.0% L1:41.9% BI: 4.2%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0m8x8 transform intra:80.4% inter:83.2%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mcoded y,uvDC,uvAC intra: 32.3% 35.6% 6.1% inter: 6.5% 6.4% 0.1%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mi16 v,h,dc,p: 45% 24% 22%  9%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 26% 19% 44%  2%  2%  2%  2%  2%  2%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 30% 22% 13%  4%  7%  8%  8%  5%  4%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mi8c dc,h,v,p: 57% 20% 21%  3%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mWeighted P-Frames: Y:0.2% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mref P L0: 73.5%  9.6% 12.5%  4.3%  0.0%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mref B L0: 86.4% 10.6%  3.0%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mref B L1: 96.8%  3.2%\n",
            "\u001b[1;36m[libx264 @ 0x5d02673f17c0] \u001b[0mkb/s:1035.00\n",
            "\u001b[1;36m[aac @ 0x5d02673ef5c0] \u001b[0mQavg: 158.364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Checking whether our output file generated or not !</b></h2>"
      ],
      "metadata": {
        "id": "ONFHTer6j614"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Wav2Lip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eXxE6JSg-Ji",
        "outputId": "0faf9a4a-f6b8-40b6-9c8d-7706f670e3bc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio.py\t\tfilelists\t     outputs.mp4       results\n",
            "checkpoints\t\thparams.py\t     preprocess.py     temp\n",
            "color_syncnet_train.py\thq_wav2lip_train.py  __pycache__       wav2lip_train.py\n",
            "evaluation\t\tinference.py\t     README.md\n",
            "face_detection\t\tmodels\t\t     requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Copying our file to google drive !<b><h2>"
      ],
      "metadata": {
        "id": "yjFu4ApkkDr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"Wav2Lip/outputs.mp4\" \"/content/gdrive/MyDrive/Colab Notebooks/\""
      ],
      "metadata": {
        "id": "gA208RzxhWZm"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall summary:\n",
        "\n",
        "\n",
        "- This whole project depends upon input file\n",
        "- Use Jdownloader to download highest quality avaialble and then covert it using ffmpeg\n",
        "- Input file should be of 1280p (max) with 25 fps\n",
        "- Wav2lip_gan.pth must be used\n",
        "\n"
      ],
      "metadata": {
        "id": "no2M5nbpkN21"
      }
    }
  ]
}